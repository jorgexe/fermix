{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20f4f15",
   "metadata": {},
   "source": [
    "# Model Evaluation Visualizations\n",
    "## Generate ROC, PR, Confusion Matrix, and Feature Importance Plots\n",
    "\n",
    "This notebook loads the trained models and generates comprehensive evaluation visualizations.\n",
    "\n",
    "### Generated Plots:\n",
    "1. **ROC Curve** (`roc.png`) - Receiver Operating Characteristic\n",
    "2. **Precision-Recall Curve** (`pr.png`) - PR curve for imbalanced data\n",
    "3. **Confusion Matrix** (`confusion.png`) - Classification results\n",
    "4. **Feature Importance** (`feature_importance.png`) - Top features for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e5c37",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9ddc2",
   "metadata": {},
   "source": [
    "## 2. Load Models and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "models_dir = Path('../models')\n",
    "data_dir = Path('../data/clean')\n",
    "figures_dir = Path('../docs/figures')\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loading models and metadata...\")\n",
    "\n",
    "# Load models\n",
    "rf_model = joblib.load(models_dir / 'model_rf.pkl')\n",
    "lgbm_model = joblib.load(models_dir / 'model_lgbm.pkl')\n",
    "print(\"✓ Models loaded\")\n",
    "\n",
    "# Load metadata\n",
    "with open(models_dir / 'metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "print(\"✓ Metadata loaded\")\n",
    "\n",
    "# Load feature list\n",
    "with open(models_dir / 'features.json', 'r') as f:\n",
    "    features_data = json.load(f)\n",
    "    feature_cols = features_data['features']\n",
    "print(f\"✓ Feature list loaded ({len(feature_cols)} features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074355e4",
   "metadata": {},
   "source": [
    "## 3. Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d411c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "print(\"Loading test data...\")\n",
    "df = pd.read_csv(data_dir / 'kepler_clean.csv')\n",
    "\n",
    "# Create binary target (same as training)\n",
    "df_binary = df[df['koi_disposition'].isin(['CONFIRMED', 'FALSE POSITIVE'])].copy()\n",
    "df_binary['label'] = (df_binary['koi_disposition'] == 'CONFIRMED').astype(int)\n",
    "\n",
    "# Recreate train/test split (same random state as training)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_binary[feature_cols].copy()\n",
    "y = df_binary['label'].copy()\n",
    "\n",
    "# Handle missing values (same as training)\n",
    "for col in feature_cols:\n",
    "    if X[col].isnull().any():\n",
    "        X[col].fillna(X[col].median(), inplace=True)\n",
    "\n",
    "# Split (using same random state as training)\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nGenerating predictions...\")\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "y_pred_proba_lgbm = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"✓ Test set: {len(y_test):,} samples\")\n",
    "print(\"✓ Predictions generated for both models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4fbb9",
   "metadata": {},
   "source": [
    "## 4. ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c0400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curves\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "fpr_lgbm, tpr_lgbm, _ = roc_curve(y_test, y_pred_proba_lgbm)\n",
    "roc_auc_lgbm = auc(fpr_lgbm, tpr_lgbm)\n",
    "\n",
    "# Create ROC plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_rf, tpr_rf, color='blue', lw=2, \n",
    "         label=f'Random Forest (AUC = {roc_auc_rf:.3f})')\n",
    "plt.plot(fpr_lgbm, tpr_lgbm, color='green', lw=2, \n",
    "         label=f'LightGBM (AUC = {roc_auc_lgbm:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve\\nExoplanet Classification', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "roc_path = figures_dir / 'roc.png'\n",
    "plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ ROC curve saved: {roc_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2271354",
   "metadata": {},
   "source": [
    "## 5. Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee017f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PR curves\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_pred_proba_rf)\n",
    "pr_auc_rf = auc(recall_rf, precision_rf)\n",
    "\n",
    "precision_lgbm, recall_lgbm, _ = precision_recall_curve(y_test, y_pred_proba_lgbm)\n",
    "pr_auc_lgbm = auc(recall_lgbm, precision_lgbm)\n",
    "\n",
    "# Baseline (proportion of positive class)\n",
    "baseline = y_test.sum() / len(y_test)\n",
    "\n",
    "# Create PR plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall_rf, precision_rf, color='blue', lw=2, \n",
    "         label=f'Random Forest (AUC = {pr_auc_rf:.3f})')\n",
    "plt.plot(recall_lgbm, precision_lgbm, color='green', lw=2, \n",
    "         label=f'LightGBM (AUC = {pr_auc_lgbm:.3f})')\n",
    "plt.axhline(y=baseline, color='red', lw=2, linestyle='--', \n",
    "            label=f'Baseline (No Skill = {baseline:.3f})')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall Curve\\nExoplanet Classification', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower left\", fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "pr_path = figures_dir / 'pr.png'\n",
    "plt.savefig(pr_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ PR curve saved: {pr_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be040ad",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrices\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "cm_lgbm = confusion_matrix(y_test, y_pred_lgbm)\n",
    "\n",
    "# Create side-by-side confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Random Forest\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['FALSE POS', 'CONFIRMED'],\n",
    "            yticklabels=['FALSE POS', 'CONFIRMED'],\n",
    "            ax=axes[0], cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Random Forest\\nConfusion Matrix', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label', fontsize=11)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=11)\n",
    "\n",
    "# LightGBM\n",
    "sns.heatmap(cm_lgbm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['FALSE POS', 'CONFIRMED'],\n",
    "            yticklabels=['FALSE POS', 'CONFIRMED'],\n",
    "            ax=axes[1], cbar_kws={'label': 'Count'})\n",
    "axes[1].set_title('LightGBM\\nConfusion Matrix', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label', fontsize=11)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "confusion_path = figures_dir / 'confusion.png'\n",
    "plt.savefig(confusion_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Confusion matrices saved: {confusion_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc40b84",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "lgbm_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': lgbm_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "# Create side-by-side feature importance plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Random Forest\n",
    "axes[0].barh(range(len(rf_importance)), rf_importance['importance'], color='steelblue')\n",
    "axes[0].set_yticks(range(len(rf_importance)))\n",
    "axes[0].set_yticklabels(rf_importance['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Random Forest\\nTop 15 Feature Importances', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# LightGBM\n",
    "axes[1].barh(range(len(lgbm_importance)), lgbm_importance['importance'], color='seagreen')\n",
    "axes[1].set_yticks(range(len(lgbm_importance)))\n",
    "axes[1].set_yticklabels(lgbm_importance['feature'])\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[1].set_title('LightGBM\\nTop 15 Feature Importances', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "importance_path = figures_dir / 'feature_importance.png'\n",
    "plt.savefig(importance_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Feature importance plot saved: {importance_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f7221",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### ✅ Generated Visualizations:\n",
    "All evaluation plots have been saved to `docs/figures/`:\n",
    "- `roc.png` - ROC curves comparing both models\n",
    "- `pr.png` - Precision-Recall curves for imbalanced data assessment\n",
    "- `confusion.png` - Confusion matrices showing classification results\n",
    "- `feature_importance.png` - Top features driving each model's predictions\n",
    "\n",
    "These visualizations are ready to be included in the model card and documentation.\n",
    "\n",
    "---\n",
    "*Evaluation plots generated successfully!*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
